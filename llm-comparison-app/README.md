# LLM Comparison App

A React application for comparing different LLM models' SQL generation capabilities with real-time metrics.

## Features

- Compare multiple LLM models side-by-side
- Visualize performance metrics with interactive charts
- Real-time SQL quality evaluation
- Advanced SQL metrics from the SQL metrics evaluator

## Integration with SQL Metrics Evaluator

This application integrates with the SQL metrics evaluator to provide real-time metrics for SQL queries generated by different LLM models. The integration includes:

1. **API Integration**: The app calls the SQL metrics evaluator API to get real-time metrics for SQL queries.
2. **Metrics Visualization**: The app displays the metrics in various charts and tables.
3. **Fallback Mechanism**: If the SQL metrics evaluator API is not available, the app falls back to local metrics calculation.

### Available Metrics

The following metrics are available from the SQL metrics evaluator:

- **Execution Accuracy**: Measures how accurately the SQL query can be executed
- **Exact Match Accuracy**: Percentage of exact match with reference queries
- **Logical Form Accuracy**: Logical equivalence with reference queries
- **Table/Column Accuracy**: Accuracy of table and column selection
- **Join Accuracy**: Correctness of JOIN operations
- **Where Clause Accuracy**: Accuracy of filtering conditions
- **Aggregation Accuracy**: Correct use of aggregation functions
- **Group/Order Accuracy**: Proper use of GROUP BY/ORDER BY
- **Inference Latency**: Time taken to generate the query
- **Complexity Handling**: Performance across complexity levels
- **Zero-Shot Performance**: Generalization to unseen schemas

## Setup

### Prerequisites

- Node.js 14+
- npm or yarn
- SQL metrics evaluator running on http://localhost:8000

### Installation

1. Clone the repository
2. Install dependencies:
   ```
   npm install
   ```
3. Start the development server:
   ```
   npm run dev
   ```

### Environment Variables

Create a `.env` file in the root directory with the following variables:

```
VITE_API_URL=http://localhost:8000
VITE_OPENAI_API_KEY=your_openai_api_key
```

## Usage

1. Enter a natural language query or select a sample query
2. Click "Generate SQL" to get responses from all models
3. View the results and metrics for each model
4. Compare the performance of different models using the visualization tools

## Development

### Project Structure

- `src/components`: React components
- `src/services`: API services
- `src/data`: Sample data
- `src/styles`: CSS styles

### Adding New Models

To add a new model:

1. Update the `MODEL_CONFIG` in `src/services/api.ts`
2. Add a new query function in `src/services/api.ts`
3. Update the `sequentialQueryModels` function to include the new model
4. Update the UI components to display the new model's results

## License

MIT
